import csv

configfile: config["cfp"]

allsamples = config["allsamples"]
scriptdir = config["scriptdir"]
outdir = config["outdir"]

trimdir = outdir + "/01_trimmed"

# Create dictionary of reads indexed by sample IDs
with open(allsamples, mode='r') as infile:
    reader = csv.reader(infile)
    mydict = {rows[0]:{'a': rows[1], 'b':rows[2].strip()} for rows in reader}

Samples = list(mydict.keys())

rule all:
    input:
        expand(trimdir + '_reads/{sample}_1.trim.fastq.gz', sample=Samples),
        expand(trimdir + '_reads/{sample}_2.trim.fastq.gz', sample=Samples)

rule trim: 
	input: 
		a = lambda wildcards: mydict[wildcards.sample]['a'],
		b = lambda wildcards: mydict[wildcards.sample]['b']
	output:
		trimdir + '_reads/{sample}_1.trim.fastq.gz',
		trimdir + '_reads/{sample}_2.trim.fastq.gz'
	threads: 2
	shell:
		PEAT + " paired -1 {input.a} -2 {input.b} -o " + trimdir + "_reads/{wildcards.sample} -n {threads} -l 20 -r 0.1 -a 0.1 -g 0.1 --out_gzip"
